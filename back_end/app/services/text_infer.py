# app/services/text_infer.py
from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, List, Optional

import torch
import torch.nn as nn
import torch.nn.functional as F
import sklearn.feature_extraction.text  # noqa: F401
from transformers import BertForSequenceClassification, BertTokenizer, AutoTokenizer


# torch load ì‹œ vectorizer(TfidfVectorizer) ì•ˆì „ ê¸€ë¡œë²Œ ë“±ë¡
torch.serialization.add_safe_globals([sklearn.feature_extraction.text.TfidfVectorizer])


class Autoencoder(nn.Module):
    def __init__(self, input_dim: int):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 1024), nn.ReLU(),
            nn.Linear(1024, 256), nn.ReLU(),
            nn.Linear(256, 32),
        )
        self.decoder = nn.Sequential(
            nn.Linear(32, 256), nn.ReLU(),
            nn.Linear(256, 1024), nn.ReLU(),
            nn.Linear(1024, input_dim),
        )

    def forward(self, x):
        return self.decoder(self.encoder(x))


@dataclass
class TextInferConfig:
    device: str = "cpu"  # "cuda" or "cpu"
    ae_path: str = "assets/models/final_ae.pth"
    kobert_path: str = "assets/models/kobert"  # ë¡œì»¬ ë””ë ‰í† ë¦¬ or HF id
    threshold: float = 5500.0
    buffer_size: int = 3

    # koBERT í›„ì²˜ë¦¬ ì„¤ì •
    temp: float = 5.0
    danger_low: float = 29.5
    danger_high: float = 31.5

    safe_words: Optional[List[str]] = None


class TextInfer:
    """
    1) AE lossë¡œ ì´ìƒ ì—¬ë¶€ íŒë‹¨
    2) ì´ìƒì´ë©´ call_id ê¸°ì¤€ ìµœê·¼ Nê°œ í…ìŠ¤íŠ¸ë¥¼ koBERTë¡œ ìƒì„¸ ë¶„ì„
    3) status / loss / details / risk_score(0~1) ë°˜í™˜
    """
    def __init__(self, cfg: TextInferConfig):
        self.cfg = cfg
        self.device = torch.device(cfg.device if (cfg.device == "cuda" and torch.cuda.is_available()) else "cpu")

        # ---- AE + Vectorizer ë¡œë“œ ----
        ckpt = torch.load(cfg.ae_path, map_location=self.device, weights_only=False)
        self.input_dim: int = int(ckpt.get("input_dim", 8000))
        self.vectorizer = ckpt.get("vec")
        if self.vectorizer is None:
            raise RuntimeError("final_ae.pt checkpointì— 'vec'(TfidfVectorizer)ê°€ ì—†ìŠµë‹ˆë‹¤.")

        self.ae = Autoencoder(self.input_dim).to(self.device)
        state = ckpt.get("state", None)
        if state is None:
            # í˜¹ì‹œ state_dictë§Œ ì €ì¥ëœ ì¼€ì´ìŠ¤
            state = ckpt
        self.ae.load_state_dict(state, strict=False)
        self.ae.eval()

        # ---- koBERT ë¡œë“œ ----
        # í† í¬ë‚˜ì´ì €ëŠ” monologg/kobertë¥¼ ì“°ëŠ” íŒ¨í„´ì´ ë§ì•„ì„œ ê¸°ë³¸ì€ HF id,
        # ë¡œì»¬ì— ì €ì¥ëœ ê²½ìš° kobert_pathê°€ ë””ë ‰í† ë¦¬ì—¬ë„ ë™ì‘í•©ë‹ˆë‹¤.
        # self.tokenizer = BertTokenizer.from_pretrained("monologg/kobert")
        self.tokenizer = AutoTokenizer.from_pretrained(cfg.kobert_path, use_fast=False)
        self.bert = BertForSequenceClassification.from_pretrained(cfg.kobert_path).to(self.device)
        self.bert.eval()

        self.safe_words = cfg.safe_words or ["ì ì‹¬", "ì €ë…", "ë¨¹ì", "ì¹´í˜", "ì¹œêµ¬", "ê³ ìƒ", "ì‚¬ë‘í•´", "ë°˜ê°€ì›Œ"]

    def ae_loss(self, text: str) -> float:
        vec = self.vectorizer.transform([text]).toarray()
        x = torch.FloatTensor(vec).to(self.device)
        with torch.no_grad():
            recon = self.ae(x)
            loss = torch.mean((recon - x) ** 2).item()
        return float(loss)

    def bert_analyze(self, text: str) -> Dict[str, Any]:
        # ì¼ìƒ ëŒ€í™” í•„í„°
        if any(w in text for w in self.safe_words):
            return {"result": "âœ… ì•ˆì „", "prob": 0.0, "msg": "ì¼ìƒ ëŒ€í™” í•„í„°ë§"}

        inputs = self.tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            padding=True,
            max_length=128,
        ).to(self.device)

        with torch.no_grad():
            logits = self.bert(**inputs).logits
            probs = F.softmax(logits / self.cfg.temp, dim=-1)[0].detach().cpu().numpy()

        prob = round(float(probs[1] * 100), 2)  # 0~100
        if self.cfg.danger_low <= prob <= self.cfg.danger_high:
            return {"result": "ğŸš¨ ìœ„í—˜", "prob": prob, "msg": "í”¼ì‹± íŒ¨í„´ ê°ì§€"}
        elif 28.0 <= prob < self.cfg.danger_low:
            return {"result": "ğŸŸ  ê²½ê³ ", "prob": prob, "msg": "ì˜ì‹¬ ì •í™© í¬ì°©"}
        return {"result": "âœ… ì•ˆì „", "prob": prob, "msg": "ì •ìƒ ë¬¸ë§¥"}

    def predict(self, buffered_texts: List[str]) -> Dict[str, Any]:
        """
        buffered_texts: call_id ê¸°ì¤€ ìµœê·¼ Nê°œ(ì˜ˆ: 3ê°œ) í…ìŠ¤íŠ¸
        """
        if not buffered_texts:
            return {"status": "SAFE", "loss": 0.0, "details": None, "risk_score": 0.0}

        # AEëŠ” "ê°€ì¥ ìµœê·¼ chunk" ê¸°ì¤€ìœ¼ë¡œ ì´ìƒ ì—¬ë¶€ íŒë‹¨ (ì›í•˜ì‹œë©´ í•©ì³ì„œë„ ê°€ëŠ¥)
        latest = buffered_texts[-1]
        loss = self.ae_loss(latest)

        if loss <= self.cfg.threshold:
            return {"status": "SAFE", "loss": loss, "details": None, "risk_score": 0.0}

        # threshold ë„˜ìœ¼ë©´ ìµœê·¼ Nê°œë¥¼ koBERTë¡œ ë¶„ì„
        details = [self.bert_analyze(t) for t in buffered_texts]
        dangers = [d for d in details if d["result"] == "ğŸš¨ ìœ„í—˜"]
        warnings = [d for d in details if d["result"] == "ğŸŸ  ê²½ê³ "]

        if len(dangers) >= 1 or len(warnings) >= 2:
            status = "ğŸš¨ CRITICAL"
        else:
            status = "âœ… NORMAL"

        # risk_score (0~1) ë§Œë“¤ê¸°: details ì¤‘ ìµœê³  prob ì‚¬ìš©(0~100 -> 0~1)
        max_prob = 0.0
        for d in details:
            max_prob = max(max_prob, float(d.get("prob", 0.0)))
        risk_score = max_prob / 100.0

        return {"status": status, "loss": loss, "details": details, "risk_score": risk_score}
